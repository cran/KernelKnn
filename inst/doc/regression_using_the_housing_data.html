<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Lampros Mouselimis" />

<meta name="date" content="2025-09-14" />

<title>Regression using the Housing data</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Regression using the Housing data</h1>
<h4 class="author">Lampros Mouselimis</h4>
<h4 class="date">2025-09-14</h4>



<p>The following examples illustrate the functionality of the KernelKnn
package for <strong>regression</strong> tasks. I’ll make use of the
<em>Housing</em> data set,</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">data</span>(Boston, <span class="at">package =</span> <span class="st">&#39;KernelKnn&#39;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">str</span>(Boston)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    506 obs. of  14 variables:
##  $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
##  $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
##  $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
##  $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
##  $ rm     : num  6.58 6.42 7.18 7 7.15 ...
##  $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
##  $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
##  $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...
##  $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
##  $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
##  $ black  : num  397 397 393 395 397 ...
##  $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
##  $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</code></pre>
<p><br></p>
<p>When using an algorithm where the ouput depends on distance
calculation (as is the case in k-nearest-neighbors) it is recommended to
first scale the data,</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">scale</span>(Boston[, <span class="sc">-</span><span class="fu">ncol</span>(Boston)])</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>y <span class="ot">=</span> Boston[, <span class="fu">ncol</span>(Boston)]</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># random split of data in train and test</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>spl_train <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(y), <span class="fu">round</span>(<span class="fu">length</span>(y) <span class="sc">*</span> <span class="fl">0.75</span>))</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>spl_test <span class="ot">=</span> <span class="fu">setdiff</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(y), spl_train)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="fu">str</span>(spl_train)</span></code></pre></div>
<pre><code>##  int [1:380] 411 64 274 134 28 380 17 125 247 373 ...</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">str</span>(spl_test)</span></code></pre></div>
<pre><code>##  int [1:126] 4 12 15 18 20 24 35 37 43 47 ...</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># evaluation metric</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>mse <span class="ot">=</span> <span class="cf">function</span> (y_true, y_pred) {</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>  </span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>  out <span class="ot">=</span> <span class="fu">mean</span>((y_true <span class="sc">-</span> y_pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>  </span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>  out</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>}</span></code></pre></div>
<div id="the-kernelknn-function" class="section level2">
<h2>The KernelKnn function</h2>
<p>The KernelKnn function takes a number of arguments. To read details
for each one of the arguments type ?KernelKnn::KernelKnn in the
console.</p>
<p>A simple k-nearest-neighbors can be run with weights_function = NULL
(the parameter ‘regression’ should be set to TRUE for regression),</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">library</span>(KernelKnn)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>preds_TEST <span class="ot">=</span> <span class="fu">KernelKnn</span>(X[spl_train, ], <span class="at">TEST_data =</span> X[spl_test, ], y[spl_train], <span class="at">k =</span> <span class="dv">5</span> , </span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>                       </span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>                       <span class="at">method =</span> <span class="st">&#39;euclidean&#39;</span>, <span class="at">weights_function =</span> <span class="cn">NULL</span>, <span class="at">regression =</span> T)</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="fu">str</span>(preds_TEST)</span></code></pre></div>
<pre><code>##  num [1:126] 30.3 20.8 18 16.3 19 ...</code></pre>
<p><br> Using transf_categ_cols = TRUE, categorical features can be
either encoded to dummy or to numeric features depending on the number
of the unique values (here I convert the ‘chas’ and ‘rad’ features to
factor to apply the <em>transf_categ_cols</em> parameter)</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">apply</span>(Boston, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="fu">length</span>(<span class="fu">unique</span>(x)))</span></code></pre></div>
<pre><code>##    crim      zn   indus    chas     nox      rm     age     dis     rad     tax 
##     504      26      76       2      81     446     356     412       9      66 
## ptratio   black   lstat    medv 
##      46     357     455     229</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>tmp_bst <span class="ot">=</span> Boston</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>tmp_bst<span class="sc">$</span>chas <span class="ot">=</span> <span class="fu">as.factor</span>(tmp_bst<span class="sc">$</span>chas)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>tmp_bst<span class="sc">$</span>rad <span class="ot">=</span> <span class="fu">as.factor</span>(tmp_bst<span class="sc">$</span>rad)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>preds_TEST <span class="ot">=</span> <span class="fu">KernelKnn</span>(tmp_bst[spl_train, <span class="sc">-</span><span class="fu">ncol</span>(tmp_bst)], </span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>                       </span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>                       <span class="at">TEST_data =</span> tmp_bst[spl_test, <span class="sc">-</span><span class="fu">ncol</span>(tmp_bst)], </span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>                       </span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>                       y[spl_train], <span class="at">k =</span> <span class="dv">5</span> , <span class="at">method =</span> <span class="st">&#39;euclidean&#39;</span>, </span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>                       </span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>                       <span class="at">regression =</span> T, <span class="at">transf_categ_cols =</span> T)</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a><span class="fu">str</span>(preds_TEST)</span></code></pre></div>
<pre><code>##  num [1:126] 23.7 22.3 30.2 22.2 25.4 ...</code></pre>
<p><br> There are two ways to use a kernel in the KernelKnn function.
The <strong>first option</strong> is to choose one of the existing
kernels (<em>uniform</em>, <em>triangular</em>, <em>epanechnikov</em>,
<em>biweight</em>, <em>triweight</em>, <em>tricube</em>,
<em>gaussian</em>, <em>cosine</em>, <em>logistic</em>,
<em>silverman</em>, <em>inverse</em>, <em>gaussianSimple</em>,
<em>exponential</em>). Here, I use the <em>mahalanobis</em> metric
(which takes advantage of the covariance matrix of the data, but it
somewhat slows down training in comparison to the other distance
metrics) and the <em>biweight</em> kernel, because they give optimal
results (according to my <em>RandomSearchR</em> package),</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>preds_TEST_biw <span class="ot">=</span> <span class="fu">KernelKnn</span>(X[spl_train, ], <span class="at">TEST_data =</span> X[spl_test, ], y[spl_train], <span class="at">k =</span> <span class="dv">5</span>, </span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>                           </span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>                           <span class="at">method =</span> <span class="st">&#39;mahalanobis&#39;</span>, <span class="at">weights_function =</span> <span class="st">&#39;biweight&#39;</span>, </span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>                           </span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>                           <span class="at">regression =</span> T, <span class="at">transf_categ_cols =</span> F)</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="fu">str</span>(preds_TEST_biw)</span></code></pre></div>
<pre><code>##  num [1:126] 33.1 21.9 17 17.5 20.1 ...</code></pre>
<p><br> The <strong>second option</strong> is to give a self defined
kernel function. Here, I’ll pick the density function of the normal
distribution with mean = 0.0 and standard deviation = 1.0 (the data are
scaled to have mean zero and unit variance),</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a>norm_kernel <span class="ot">=</span> <span class="cf">function</span>(W) {</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>  </span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>  W <span class="ot">=</span> <span class="fu">dnorm</span>(W, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">1.0</span>)</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>  </span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>  W <span class="ot">=</span> W <span class="sc">/</span> <span class="fu">rowSums</span>(W)</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>  </span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>  <span class="fu">return</span>(W)</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>}</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>preds_TEST_norm <span class="ot">=</span> <span class="fu">KernelKnn</span>(X[spl_train, ], <span class="at">TEST_data =</span> X[spl_test, ], y[spl_train], <span class="at">k =</span> <span class="dv">5</span>,</span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>                            </span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a>                            <span class="at">method =</span> <span class="st">&#39;mahalanobis&#39;</span>, <span class="at">weights_function =</span> norm_kernel, </span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a>                            </span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a>                            <span class="at">regression =</span> T, <span class="at">transf_categ_cols =</span> F)</span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a><span class="fu">str</span>(preds_TEST_norm)</span></code></pre></div>
<pre><code>##  num [1:126] 30.3 22.3 17 16.3 19.9 ...</code></pre>
<p><br></p>
<p>The computations can be speed up by using the parameter
<strong>threads</strong> (multiple cores can be run in parallel). There
is also the option to exclude <strong>extrema</strong> (minimum and
maximum distances) during the calculation of the k-nearest-neighbor
distances using extrema = TRUE. The <em>bandwidth</em> of the existing
kernels can be tuned using the <strong>h</strong> parameter. <br></p>
<p>K-nearest-neigbor calculations in the KernelKnn function can be
accomplished using the following distance metrics : <em>euclidean</em>,
<em>manhattan</em>, <em>chebyshev</em>, <em>canberra</em>,
<em>braycurtis</em>, <em>minkowski</em> (by default the order ‘p’ of the
minkowski parameter equals k), <em>hamming</em>, <em>mahalanobis</em>,
<em>pearson_correlation</em>, <em>simple_matching_coefficient</em>,
<em>jaccard_coefficient</em> and <em>Rao_coefficient</em>. The last four
are similarity measures and are appropriate for binary data [0,1].
<br></p>
<p>I employed my RandomSearchR package to find the optimal parameters
for the KernelKnn function and the following two pairs of parameters
give an optimal mean-squared-error, <br> <br></p>
<table>
<thead>
<tr class="header">
<th align="right">k</th>
<th align="left">method</th>
<th align="left">kernel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">9</td>
<td align="left">mahalanobis</td>
<td align="left">triweight</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="left">canberra</td>
<td align="left">cosine</td>
</tr>
</tbody>
</table>
</div>
<div id="the-kernelknncv-function" class="section level2">
<h2>The KernelKnnCV function</h2>
<p>I’ll use the <em>KernelKnnCV</em> function to calculate the
mean-squared-error using 3-fold cross-validation for the previous
mentioned parameter pairs,</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>fit_cv_pair1 <span class="ot">=</span> <span class="fu">KernelKnnCV</span>(X, y, <span class="at">k =</span> <span class="dv">9</span>, <span class="at">folds =</span> <span class="dv">3</span>, <span class="at">method =</span> <span class="st">&#39;mahalanobis&#39;</span>, </span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>                           </span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>                           <span class="at">weights_function =</span> <span class="st">&#39;triweight&#39;</span>, <span class="at">regression =</span> T, </span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>                           </span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>                           <span class="at">threads =</span> <span class="dv">5</span>, <span class="at">seed_num =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="fu">str</span>(fit_cv_pair1)</span></code></pre></div>
<pre><code>## List of 2
##  $ preds:List of 3
##   ..$ : num [1:169] 26.3 26 28.3 21.8 21.4 ...
##   ..$ : num [1:168] 19.6 17.4 15.9 17.4 14.3 ...
##   ..$ : num [1:169] 23.2 22.7 29.8 22.7 22.9 ...
##  $ folds:List of 3
##   ..$ fold_1: int [1:169] 3 4 5 12 13 19 20 21 25 26 ...
##   ..$ fold_2: int [1:168] 7 8 9 18 24 27 29 36 40 41 ...
##   ..$ fold_3: int [1:169] 1 2 6 10 11 14 15 16 17 22 ...</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>fit_cv_pair2 <span class="ot">=</span> <span class="fu">KernelKnnCV</span>(X, y, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">folds =</span> <span class="dv">3</span>, <span class="at">method =</span> <span class="st">&#39;canberra&#39;</span>,</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>                           </span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>                           <span class="at">weights_function =</span> <span class="st">&#39;cosine&#39;</span>, <span class="at">regression =</span> T, </span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a>                           </span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a>                           <span class="at">threads =</span> <span class="dv">5</span>, <span class="at">seed_num =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="fu">str</span>(fit_cv_pair2)</span></code></pre></div>
<p><br></p>
<p>Each cross-validated object returns a list of length 2 ( the first
sublist includes the predictions for each fold whereas the second gives
the indices of the folds)</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>mse_pair1 <span class="ot">=</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(fit_cv_pair1<span class="sc">$</span>preds), </span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>                          </span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>                          <span class="cf">function</span>(x) <span class="fu">mse</span>(y[fit_cv_pair1<span class="sc">$</span>folds[[x]]], </span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>                                          </span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>                                          fit_cv_pair1<span class="sc">$</span>preds[[x]])))</span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a>mse_pair1</span></code></pre></div>
<pre><code>## [1] 19.03225 19.47981 19.41959</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&#39;mse for params_pair1 is :&#39;</span>, <span class="fu">mean</span>(mse_pair1), <span class="st">&#39;</span><span class="sc">\n</span><span class="st">&#39;</span>)</span></code></pre></div>
<pre><code>## mse for params_pair1 is : 19.31055</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>mse_pair2 <span class="ot">=</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(fit_cv_pair2<span class="sc">$</span>preds), </span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>                          </span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>                          <span class="cf">function</span>(x) <span class="fu">mse</span>(y[fit_cv_pair2<span class="sc">$</span>folds[[x]]], </span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>                                          </span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a>                                          fit_cv_pair2<span class="sc">$</span>preds[[x]])))</span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>mse_pair2</span></code></pre></div>
<pre><code>## [1] 17.83355 29.86579 28.65615</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&#39;mse for params_pair2 is :&#39;</span>, <span class="fu">mean</span>(mse_pair2), <span class="st">&#39;</span><span class="sc">\n</span><span class="st">&#39;</span>)</span></code></pre></div>
<pre><code>## mse for params_pair2 is : 25.45183</code></pre>
<p><br></p>
</div>
<div id="adding-or-multiplying-kernels" class="section level2">
<h2>Adding or multiplying kernels</h2>
<p>In the KernelKnn package there is also the option to <strong>combine
kernels</strong> (adding or multiplying) from the existing ones. For
instance, if I want to multiply the <em>tricube</em> with the
<em>gaussian</em> kernel, then I’ll give the following character string
to the weights_function, <em>“tricube_gaussian_MULT”</em>. On the other
hand, If I want to add the same kernels then the weights_function will
be <em>“tricube_gaussian_ADD”</em>. I experimented with my RandomSearchR
package combining the different kernels and the following two parameter
settings gave optimal results,</p>
<p><br></p>
<table>
<thead>
<tr class="header">
<th align="right">k</th>
<th align="left">method</th>
<th align="left">kernel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">19</td>
<td align="left">mahalanobis</td>
<td align="left">triangular_triweight_MULT</td>
</tr>
<tr class="even">
<td align="right">18</td>
<td align="left">mahalanobis</td>
<td align="left">biweight_triweight_gaussian_MULT</td>
</tr>
</tbody>
</table>
<p><br></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>fit_cv_pair1 <span class="ot">=</span> <span class="fu">KernelKnnCV</span>(X, y, <span class="at">k =</span> <span class="dv">19</span>, <span class="at">folds =</span> <span class="dv">3</span>, <span class="at">method =</span> <span class="st">&#39;mahalanobis&#39;</span>, </span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>                           </span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>                           <span class="at">weights_function =</span> <span class="st">&#39;triangular_triweight_MULT&#39;</span>, </span>
<span id="cb31-4"><a href="#cb31-4" tabindex="-1"></a>                           </span>
<span id="cb31-5"><a href="#cb31-5" tabindex="-1"></a>                           <span class="at">regression =</span> T, <span class="at">threads =</span> <span class="dv">5</span>, <span class="at">seed_num =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="fu">str</span>(fit_cv_pair1)</span></code></pre></div>
<pre><code>## List of 2
##  $ preds:List of 3
##   ..$ : num [1:169] 26.4 26 27.8 21.5 21.8 ...
##   ..$ : num [1:168] 19.7 17.6 16.4 16.7 14.6 ...
##   ..$ : num [1:169] 23.1 22.7 29 22.3 22.3 ...
##  $ folds:List of 3
##   ..$ fold_1: int [1:169] 3 4 5 12 13 19 20 21 25 26 ...
##   ..$ fold_2: int [1:168] 7 8 9 18 24 27 29 36 40 41 ...
##   ..$ fold_3: int [1:169] 1 2 6 10 11 14 15 16 17 22 ...</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a>fit_cv_pair2 <span class="ot">=</span> <span class="fu">KernelKnnCV</span>(X, y, <span class="at">k =</span> <span class="dv">18</span>, <span class="at">folds =</span> <span class="dv">3</span>, <span class="at">method =</span> <span class="st">&#39;mahalanobis&#39;</span>, </span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a>                           </span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a>                           <span class="at">weights_function =</span> <span class="st">&#39;biweight_triweight_gaussian_MULT&#39;</span>, </span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a>                           </span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a>                           <span class="at">regression =</span> T, <span class="at">threads =</span> <span class="dv">5</span>, <span class="at">seed_num =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a><span class="fu">str</span>(fit_cv_pair2)</span></code></pre></div>
<pre><code>## List of 2
##  $ preds:List of 3
##   ..$ : num [1:169] 26.2 26 28.1 21.7 21.7 ...
##   ..$ : num [1:168] 19.7 17.6 16.4 16.7 14.6 ...
##   ..$ : num [1:169] 23.1 22.8 29.2 22.4 22.2 ...
##  $ folds:List of 3
##   ..$ fold_1: int [1:169] 3 4 5 12 13 19 20 21 25 26 ...
##   ..$ fold_2: int [1:168] 7 8 9 18 24 27 29 36 40 41 ...
##   ..$ fold_3: int [1:169] 1 2 6 10 11 14 15 16 17 22 ...</code></pre>
<p><br></p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a>mse_pair1 <span class="ot">=</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(fit_cv_pair1<span class="sc">$</span>preds), </span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>                          </span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a>                          <span class="cf">function</span>(x) <span class="fu">mse</span>(y[fit_cv_pair1<span class="sc">$</span>folds[[x]]], </span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a>                                          </span>
<span id="cb37-5"><a href="#cb37-5" tabindex="-1"></a>                                          fit_cv_pair1<span class="sc">$</span>preds[[x]])))</span>
<span id="cb37-6"><a href="#cb37-6" tabindex="-1"></a>mse_pair1</span></code></pre></div>
<pre><code>## [1] 19.18593 19.42827 17.33437</code></pre>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&#39;mse for params_pair1 is :&#39;</span>, <span class="fu">mean</span>(mse_pair1), <span class="st">&#39;</span><span class="sc">\n</span><span class="st">&#39;</span>)</span></code></pre></div>
<pre><code>## mse for params_pair1 is : 18.64952</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a>mse_pair2 <span class="ot">=</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(fit_cv_pair2<span class="sc">$</span>preds), </span>
<span id="cb41-2"><a href="#cb41-2" tabindex="-1"></a>                          </span>
<span id="cb41-3"><a href="#cb41-3" tabindex="-1"></a>                          <span class="cf">function</span>(x) <span class="fu">mse</span>(y[fit_cv_pair2<span class="sc">$</span>folds[[x]]], </span>
<span id="cb41-4"><a href="#cb41-4" tabindex="-1"></a>                                          </span>
<span id="cb41-5"><a href="#cb41-5" tabindex="-1"></a>                                          fit_cv_pair2<span class="sc">$</span>preds[[x]])))</span>
<span id="cb41-6"><a href="#cb41-6" tabindex="-1"></a>mse_pair2</span></code></pre></div>
<pre><code>## [1] 19.20290 19.31054 17.56264</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&#39;mse for params_pair2 is :&#39;</span>, <span class="fu">mean</span>(mse_pair2), <span class="st">&#39;</span><span class="sc">\n</span><span class="st">&#39;</span>)</span></code></pre></div>
<pre><code>## mse for params_pair2 is : 18.69202</code></pre>
<p><br></p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
